# ğŸ“˜ GuÃ­a de Usuario - Reddit URL Scraper

**Para usuarios no tÃ©cnicos** - GuÃ­a simple y paso a paso

---

## ğŸ¯ Â¿QuÃ© hace este sistema?

Este sistema recopila automÃ¡ticamente **todas las URLs** (enlaces) compartidas en posts de Reddit de los subreddits que tÃº elijas.

**Ejemplo prÃ¡ctico:**
- Quieres ver todos los proyectos que la gente comparte en r/SideProject
- El sistema revisa todos los posts y extrae los enlaces (sitios web, apps, demos)
- Guarda todo en una base de datos para que puedas verlos fÃ¡cilmente

---

## ğŸš€ Inicio RÃ¡pido

### Paso 1: Abrir el Dashboard

1. **Doble clic** en el archivo `START_DASHBOARD.bat` (Windows) o ejecuta el comando en terminal
2. Espera unos segundos hasta que veas: `Running on http://127.0.0.1:3010`
3. Abre tu navegador en: **http://localhost:3010**

### Paso 2: Configurar Subreddits

1. En el dashboard, haz clic en el botÃ³n **âš™ï¸ Settings** (arriba a la derecha)
2. VerÃ¡s una lista de subreddits actuales
3. Para agregar uno nuevo:
   - Escribe el nombre SIN "r/" (ejemplo: `startups`, no `r/startups`)
   - Presiona Enter o clic en el botÃ³n "+"
4. Para eliminar uno: clic en la âŒ al lado del nombre

**Subreddits recomendados para proyectos:**
- `SideProject` - Proyectos personales y startups
- `startups` - Startups y emprendimiento
- `entrepreneur` - Negocios y emprendedores
- `AlphaAndBetaUsers` - Gente buscando beta testers
- `InternetIsBeautiful` - Sitios web interesantes
- `SomebodyMakeThis` - Ideas de proyectos

### Paso 3: Recopilar URLs

Una vez configurados los subreddits:

1. Haz clic en **âš¡ Fetch URLs**
2. El sistema comenzarÃ¡ a buscar automÃ¡ticamente
3. VerÃ¡s el progreso en tiempo real
4. Cuando termine, verÃ¡s: "âœ… Completado"

**â±ï¸ Tiempo estimado:** 
- Daily (actualizaciÃ³n diaria): 1-2 minutos
- Backfill (histÃ³rico): 5-10 minutos

---

## ğŸ“Š CÃ³mo Usar el Dashboard

### Vista Principal

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Reddit URL Scraper          âš™ï¸ Settings  âš¡ Fetchâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚  ğŸ“Š 3,866 URLs collected                        â”‚
â”‚  ğŸ“… Last update: 2 hours ago                    â”‚
â”‚                                                 â”‚
â”‚  ğŸ” Search: [_______________]  ğŸ—‚ï¸ All Subredditsâ”‚
â”‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Post Title                              â”‚   â”‚
â”‚  â”‚ URL: https://example.com                â”‚   â”‚
â”‚  â”‚ r/SideProject â€¢ 2026-01-30              â”‚   â”‚
â”‚  â”‚ [ğŸ”— Visit] [ğŸ—‘ï¸ Delete]                  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                 â”‚
â”‚  [â† Previous]  Page 1 of 78  [Next â†’]         â”‚
â”‚                                                 â”‚
â”‚  [ğŸ“¥ Export CSV]                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Funciones Disponibles

#### ğŸ” **Buscar**
- Escribe cualquier palabra (ejemplo: "AI", "marketplace", "notion")
- Busca en tÃ­tulos de posts y URLs
- Actualiza resultados en tiempo real

#### ğŸ—‚ï¸ **Filtrar por Subreddit**
- Desplegable "All Subreddits"
- Selecciona uno especÃ­fico para ver solo esos posts

#### ğŸ”— **Visit (Visitar)**
- Abre el enlace en una nueva pestaÃ±a
- Te lleva directo al sitio web o proyecto

#### ğŸ—‘ï¸ **Delete (Eliminar)**
- Elimina una URL especÃ­fica de tu base de datos
- Ãštil para limpiar enlaces rotos o irrelevantes

#### ğŸ“¥ **Export CSV**
- Descarga todos los datos en formato Excel/CSV
- Incluye: tÃ­tulo, URL, subreddit, fecha
- Perfecto para anÃ¡lisis o compartir con tu equipo

---

## ğŸ”„ Modos de RecopilaciÃ³n

### ğŸŸ¢ Daily (Recomendado para uso normal)

**Â¿QuÃ© hace?**
- Busca solo posts **nuevos** desde tu Ãºltima actualizaciÃ³n
- RÃ¡pido (1-2 minutos)
- Ideal para ejecutar diariamente

**CuÃ¡ndo usar:**
- Tienes el histÃ³rico completo
- Solo quieres actualizaciones diarias
- Quieres resultados rÃ¡pidos

**CÃ³mo ejecutar:**
1. Clic en âš¡ Fetch URLs
2. Selecciona "Daily (new posts only)"
3. Clic en "Start"

---

### ğŸ”µ Backfill (Para obtener historial)

**Â¿QuÃ© hace?**
- Busca posts **histÃ³ricos** (hasta 180 dÃ­as atrÃ¡s)
- MÃ¡s lento (5-10 minutos)
- Obtiene mucha mÃ¡s informaciÃ³n

**CuÃ¡ndo usar:**
- Primera vez que usas el sistema
- Agregaste un subreddit nuevo
- Quieres completar datos faltantes

**CÃ³mo ejecutar:**
1. Clic en âš¡ Fetch URLs
2. Selecciona "Backfill (historical)"
3. Elige cuÃ¡ntos dÃ­as (30, 90, 180)
4. Clic en "Start"

**âš ï¸ Importante:** No uses Backfill todos los dÃ­as, es innecesario y lento.

---

## ğŸ’¡ Casos de Uso Comunes

### Caso 1: Monitoreo Diario de Proyectos

**Objetivo:** Ver nuevos proyectos que se comparten cada dÃ­a

**Pasos:**
1. Configura subreddits: `SideProject`, `startups`, `AlphaAndBetaUsers`
2. Cada maÃ±ana: abre dashboard â†’ clic en âš¡ Fetch URLs (Daily)
3. Revisa los nuevos enlaces agregados
4. Visita los que te interesen

**Resultado:** Siempre al dÃ­a con nuevos proyectos y startups

---

### Caso 2: InvestigaciÃ³n de Mercado

**Objetivo:** Analizar quÃ© tipo de productos se estÃ¡n lanzando

**Pasos:**
1. Backfill de 90 dÃ­as en `SideProject`
2. Export CSV para anÃ¡lisis
3. Busca palabras clave especÃ­ficas (ej: "AI", "productivity", "B2B")
4. Analiza tendencias

**Resultado:** Reporte completo de lanzamientos recientes

---

### Caso 3: Encontrar Competencia

**Objetivo:** Ver quÃ© proyectos similares al tuyo existen

**Pasos:**
1. Configura subreddits relevantes a tu nicho
2. Usa la bÃºsqueda con keywords de tu producto
3. Visita los enlaces similares
4. Analiza sus enfoques

**Resultado:** Lista de competidores y alternativas

---

## ğŸ“ Preguntas Frecuentes (FAQ)

### â“ Â¿Cada cuÃ¡nto debo ejecutar el scraper?

**Respuesta:** Depende de tus necesidades:
- **Diario:** Si quieres estar al dÃ­a con nuevos proyectos
- **Semanal:** Si solo revisas periÃ³dicamente
- **Cuando necesites:** El sistema guarda todo, puedes ejecutarlo cuando quieras

### â“ Â¿CuÃ¡ntos subreddits puedo agregar?

**Respuesta:** Todos los que quieras, pero considera:
- MÃ¡s subreddits = mÃ¡s tiempo de scraping
- Recomendamos 3-5 para empezar
- Puedes agregar/quitar cuando quieras

### â“ Â¿Los datos se guardan permanentemente?

**Respuesta:** SÃ­, todo se guarda en una base de datos local:
- No se pierde al cerrar el navegador
- Puedes acumular datos por meses
- Solo se pierde si borras el archivo `reddit_urls.db`

### â“ Â¿QuÃ© pasa si veo URLs duplicadas?

**Respuesta:** El sistema automÃ¡ticamente:
- Detecta URLs duplicadas
- Solo guarda una versiÃ³n
- Si aparecen duplicados, son posts diferentes con el mismo enlace

### â“ Â¿Puedo usar esto en diferentes computadoras?

**Respuesta:** SÃ­, pero cada computadora tiene su propia base de datos:
- **OpciÃ³n 1:** Usa Export CSV para transferir datos
- **OpciÃ³n 2:** Copia el archivo `reddit_urls.db` entre computadoras
- **OpciÃ³n 3:** Instala en un servidor para acceso remoto

### â“ Â¿Es legal scrapear Reddit?

**Respuesta:** SÃ­, este sistema:
- Usa datos pÃºblicos de Reddit
- Respeta las reglas de rate limiting
- No requiere login ni acceso privado
- Es similar a usar Reddit normalmente

### â“ Â¿Necesito una cuenta de Reddit?

**Respuesta:** No, el sistema funciona sin autenticaciÃ³n.

### â“ Â¿QuÃ© hago si el scraping falla?

**Respuesta:** Revisa:
1. Â¿Tienes internet?
2. Â¿Reddit estÃ¡ funcionando? (visita reddit.com)
3. Intenta de nuevo en 5 minutos (puede ser rate limiting temporal)
4. Si persiste, contacta soporte

---

## ğŸ“ Tips y Mejores PrÃ¡cticas

### âœ… Hazlo

- **Ejecuta Daily regularmente** - MantÃ©n tu base de datos actualizada
- **Usa la bÃºsqueda** - Filtra por keywords relevantes
- **Exporta regularmente** - Haz backups de tus datos
- **Limpia URLs irrelevantes** - MantÃ©n tu base de datos limpia
- **Prueba diferentes subreddits** - Encuentra comunidades activas

### âŒ Evita

- **No ejecutes Backfill diario** - Es innecesario y lento
- **No agregues demasiados subreddits** - Empieza con 3-5
- **No cierres durante scraping** - Espera a que termine
- **No borres reddit_urls.db** - Es tu base de datos principal

---

## ğŸ†˜ SoluciÃ³n de Problemas

### Problema: "No se abre el dashboard"

**SoluciÃ³n:**
1. Verifica que el puerto 3010 no estÃ© en uso
2. Cierra otras instancias del programa
3. Reinicia el sistema

### Problema: "No encuentra nuevas URLs"

**Posibles causas:**
- No hay posts nuevos en ese subreddit
- Ya tienes todos los posts recientes
- El subreddit estÃ¡ poco activo

**SoluciÃ³n:** Prueba con un subreddit mÃ¡s activo o usa Backfill

### Problema: "Scraping muy lento"

**Causas comunes:**
- EstÃ¡s usando Backfill con muchos dÃ­as
- Internet lento
- Rate limiting de Reddit

**SoluciÃ³n:** 
- Usa Daily en lugar de Backfill
- Reduce el nÃºmero de dÃ­as en Backfill
- Espera unos minutos e intenta de nuevo

### Problema: "Error al exportar CSV"

**SoluciÃ³n:**
1. Cierra el archivo CSV si estÃ¡ abierto en Excel
2. Intenta exportar con otro nombre
3. Verifica permisos de escritura en la carpeta

---

## ğŸ“ Soporte

Si tienes problemas no listados aquÃ­:

1. **Revisa los logs** - El dashboard muestra mensajes de error
2. **Intenta reiniciar** - Cierra y vuelve a abrir el sistema
3. **Documenta el error** - Toma captura de pantalla
4. **Contacta soporte** - Incluye detalles del error

---

## ğŸ‰ Â¡Listo para Empezar!

Ya tienes todo lo necesario para:
- âœ… Configurar el sistema
- âœ… Recopilar URLs de Reddit
- âœ… Buscar y filtrar proyectos
- âœ… Exportar datos para anÃ¡lisis

**Siguiente paso:** Abre el dashboard y comienza a explorar proyectos interesantes!

---

**Ãšltima actualizaciÃ³n:** Enero 2026  
**VersiÃ³n:** 1.0  
**Soporte:** Consulta el archivo README.md para detalles tÃ©cnicos
